__license__ = 'GPL v3'
__copyright__ = '2008, Kovid Goyal <kovid at kovidgoyal.net>'

'''
Fetch Heise Newsticker Classic.
'''

from calibre.web.feeds.news import BasicNewsRecipe
import os

class heiseDe(BasicNewsRecipe):

    title = 'heise'
    description = 'Computernews from Germany'
    __author__ = 'Alexander Wessel'
    use_embedded_content = False
    language = 'de'
    timefmt = ' [%d %b %Y]'
    no_stylesheets = True

    # Compress images to keep article size under control
    compress_news_images = True
    compress_news_images_max_size = 100  # Max size in KB per image (Calibre compresses to ~this size)
    scale_news_images = (1280, 720)  # Max width and height in pixels

    remove_tags = [
        dict(name='footer'),
        dict(name='p', attrs={'class': 'printversion__back-to-article printversion--hide'}),
        dict(name='figure', attrs={'class': 'printversion__logo'}),
        dict(name='div', attrs={'id': 'wtma_teaser_ho_vertrieb_inline_branding'}),
        dict(name='div', attrs={'id': 'topnavimodule'}),
        dict(name='div', attrs={'class': 'notification-links'}),
        dict(name='nav')
       ]

    def preprocess_html(self, soup):
        # Remove header tags that don't have the class "article-header"
        for header in soup.find_all('header'):
            header_classes = header.get('class', [])
            if 'article-header' not in header_classes:
                header.decompose()

        # Handle Heise's custom <a-img> lazy-loaded images
        for a_img in soup.find_all('a-img'):
            # Get the real image URL from the a-img element
            img_src = a_img.get('src')
            if img_src and not img_src.startswith('data:'):
                # Create a new img tag with the real source
                new_img = soup.new_tag('img')
                new_img['src'] = img_src

                # Copy other useful attributes
                if a_img.get('alt'):
                    new_img['alt'] = a_img['alt']
                if a_img.get('width'):
                    new_img['width'] = a_img['width']
                if a_img.get('height'):
                    new_img['height'] = a_img['height']

                # Replace the a-img element with the new img tag
                a_img.replace_with(new_img)

        return soup

    def parse_index(self):
        from urllib.parse import urljoin

        # Get max article count from environment variable, default to 100
        max_articles = int(os.environ.get("HEISE_ARTICLE_COUNT", "50"))
        self.log(f'Maximum articles to fetch: {max_articles}')

        all_articles = []
        base_url = 'https://www.heise.de'
        total_articles = 0

        # Loop through pages 1-5 of the newsticker classic
        for page_num in range(1, 6):
            if total_articles >= max_articles:
                self.log(f'Reached maximum article count ({max_articles}), stopping')
                break
            page_url = f'https://www.heise.de/newsticker/classic/seite-{page_num}/'

            self.log(f'Fetching page {page_num}: {page_url}')
            soup = self.index_to_soup(page_url)

            # Find all article elements
            for article in soup.find_all('article'):
                if total_articles >= max_articles:
                    break

                # Skip sponsored articles
                article_classes = article.get('class', [])
                if 'a-article-teaser--sponsored' in article_classes:
                    continue

                # Find the first link in the article
                link_elem = article.find('a')
                if not link_elem or not link_elem.get('href'):
                    continue

                # Skip template placeholders (contains ${...})
                href = link_elem.get('href', '')
                if '${' in href:
                    continue

                # Get the URL
                url = urljoin(base_url, href)

                # Get the title from the title attribute of the link
                title = link_elem.get('title', '').strip()

                # Skip template placeholders in title
                if '${' in title or not title:
                    # Fallback to link text if no title attribute or template
                    title = link_elem.get_text(strip=True) or ''
                    if '${' in title or not title:
                        continue

                # Get the description from any <p> tag in the article
                desc_elem = article.find('p')
                description = desc_elem.get_text(strip=True) if desc_elem else ''

                page = {'title': title,
                        'url': self.get_article_url(url),
                        'description': description
                       }
                all_articles.append(page)
                self.log(f'Found page {page}')
                total_articles += 1

            self.log(f'Fetched page {page_num}, total articles so far: {total_articles}')

        # Return all articles in a single section with empty title to avoid chapter breaks and TOC
        return [('', all_articles)]

    def get_article_url(self, url):
        sep = '&' if '?' in url else '?'
        return url + f"{sep}view=print&seite=all"

    def get_browser(self):
        br = BasicNewsRecipe.get_browser(self)
        def select_form(form):
            return form.attrs.get('action', None) == '/sso/login/login/nojs'

        if os.environ.get("HEISE_USER") is not None and os.environ.get("HEISE_PASSWORD") is not None:
            br.open('https://www.heise.de/sso/login')
            br.select_form(predicate=select_form)
            ctrl_user = br.form.find_control(id='login-user')
            ctrl_user.value = os.environ["HEISE_USER"]
            ctrl_pwd = br.form.find_control(id='login-password')
            ctrl_pwd.value = os.environ["HEISE_PASSWORD"]
            br.submit()
        else: print("HEISE_USER and HEISE_PASSWORD env parameter missing for login, skipped.")
        return br
